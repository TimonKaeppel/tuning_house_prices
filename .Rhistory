colnames(train)
colnames(combined)
#df <- rbind(train, combined)
#print(head(df))
train <- read.csv("D:/Documents/DHBW Ravensburg/6. Semester/Tuning von Algorithmen/tuning_house_prices/resources/train.csv")
test <- read.csv("D:/Documents/DHBW Ravensburg/6. Semester/Tuning von Algorithmen/tuning_house_prices/resources/test.csv")
solution <- read.csv("D:/Documents/DHBW Ravensburg/6. Semester/Tuning von Algorithmen/tuning_house_prices/resources/solution.csv")
print(head(test))
if (nrow(test) == nrow(solution)) {
combined <- merge(test, solution)
print(head(combined))
}
if (nrow(test) == nrow(solution)) {
combined <- merge(test, solution)
print(head(combined))
}
colnames(train)
colnames(combined)
#df <- rbind(train, combined)
#print(head(df))
df <- rbind(train, combined)
print(head(df))
install.packages("caret")
install.packages("ranger")
library(caret)
folds <- 5
trainControl <- trainControl(method = "cv", number = folds)
library(ranger)
# Parameter für den Random Forest
rfParams <- list(ntree = 500, mtry = 3) # Anzahl der Bäume und Anzahl der Variablen pro Split
# Training mit k-fold Cross-Validation
rfModel <- train(SalePrice ~ ., data = df, method = "ranger", trControl = trainControl, tuneGrid = rfParams)
install.packages("caret")
install.packages("caret")
install.packages("caret")
install.packages("caret")
install.packages("caret")
install.packages("caret")
install.packages("ranger")
library(caret)
install.packages("caret")
install.packages("caret")
install.packages("caret")
install.packages("ranger")
library(caret)
folds <- 5
trainControl <- trainControl(method = "cv", number = folds)
library(ranger)
# Parameter für den Random Forest
rfParams <- list(ntree = 500, mtry = 3) # Anzahl der Bäume und Anzahl der Variablen pro Split
# Training mit k-fold Cross-Validation
rfModel <- train(SalePrice ~ ., data = df, method = "ranger", trControl = trainControl, tuneGrid = rfParams)
install.packages("caret")
#install.packages("caret")
#install.packages("ranger")
library(caret)
folds <- 5
trainControl <- trainControl(method = "cv", number = folds)
library(ranger)
# Parameter für den Random Forest
rfParams <- list(ntree = 500, mtry = 3) # Anzahl der Bäume und Anzahl der Variablen pro Split
# Training mit k-fold Cross-Validation
rfModel <- train(SalePrice ~ ., data = df, method = "ranger", trControl = trainControl, tuneGrid = rfParams)
library(caret)
# Identifiziere numerische und nominale Variablen
numerische_spalten <- sapply(df, is.numeric)
nominale_spalten <- !numerische_spalten
# Impute fehlende Werte für numerische Variablen mit dem Median
df[, numerische_spalten] <- preProcess(df[, numerische_spalten], method = "medianImpute")
library(caret)
# Identifiziere numerische und nominale Variablen
numerische_spalten <- sapply(df, is.numeric)
nominale_spalten <- !numerische_spalten
# Impute fehlende Werte für numerische Variablen mit dem Median
imputations_modell_numerisch <- preProcess(df[, numerische_spalten], method = "medianImpute")
df[, numerische_spalten] <- predict(imputations_modell_numerisch, df[, numerische_spalten])
# Impute fehlende Werte für nominale Variablen mit dem häufigsten Wert
imputations_modell_nominale <- preProcess(df[, nominale_spalten], method = "modeImpute")
library(caret)
# Identifiziere numerische und nominale Variablen
numerische_spalten <- sapply(df, is.numeric)
nominale_spalten <- !numerische_spalten
# Impute fehlende Werte für numerische Variablen mit dem Median
imputations_modell_numerisch <- preProcess(df[, numerische_spalten], method = "medianImpute")
df[, numerische_spalten] <- predict(imputations_modell_numerisch, df[, numerische_spalten])
# Impute fehlende Werte für nominale Variablen mit dem häufigsten Wert
for (spalte in colnames(df[, nominale_spalten])) {
häufigster_wert <- names(which.max(table(df[, spalte])))
df[, spalte][is.na(df[, spalte])] <- häufigster_wert
}
df <- subset(df, select = -id)
View(df)
library(caret)
# Identifiziere numerische und nominale Variablen
numerische_spalten <- sapply(df, is.numeric)
nominale_spalten <- !numerische_spalten
# Impute fehlende Werte für numerische Variablen mit dem Median
imputations_modell_numerisch <- preProcess(df[, numerische_spalten], method = "medianImpute")
df[, numerische_spalten] <- predict(imputations_modell_numerisch, df[, numerische_spalten])
# Impute fehlende Werte für nominale Variablen mit dem häufigsten Wert
for (spalte in colnames(df[, nominale_spalten])) {
häufigster_wert <- names(which.max(table(df[, spalte])))
df[, spalte][is.na(df[, spalte])] <- häufigster_wert
}
df <- subset(df, select = -Id)
print(df.head)
print(df.head())
print(head(df))
#install.packages("caret")
#install.packages("ranger")
library(caret)
folds <- 5
trainControl <- trainControl(method = "cv", number = folds)
library(ranger)
# Parameter für den Random Forest
rfParams <- list(ntree = 500, mtry = 3) # Anzahl der Bäume und Anzahl der Variablen pro Split
# Training mit k-fold Cross-Validation
rfModel <- train(SalePrice ~ ., data = df, method = "ranger", trControl = trainControl, tuneGrid = rfParams)
train <- read.csv("D:/Documents/DHBW Ravensburg/6. Semester/Tuning von Algorithmen/tuning_house_prices/resources/train.csv")
test <- read.csv("D:/Documents/DHBW Ravensburg/6. Semester/Tuning von Algorithmen/tuning_house_prices/resources/test.csv")
solution <- read.csv("D:/Documents/DHBW Ravensburg/6. Semester/Tuning von Algorithmen/tuning_house_prices/resources/solution.csv")
df <- read.csv("D:/Documents/DHBW Ravensburg/6. Semester/Tuning von Algorithmen/tuning_house_prices/resources/house_prices_df.csv")
#install.packages("caret")
#install.packages("ranger")
library(caret)
folds <- 5
trainControl <- trainControl(method = "cv", number = folds)
library(ranger)
# Parameter für den Random Forest
rfParams <- list(ntree = 500, mtry = 3) # Anzahl der Bäume und Anzahl der Variablen pro Split
# Training mit k-fold Cross-Validation
rfModel <- train(SalePrice ~ ., data = df, method = "ranger", trControl = trainControl, tuneGrid = rfParams)
#install.packages("caret")
#install.packages("ranger")
library(ranger)
library(caret)
# Gitter von Werten für den Parameter mtry
rfGrid <- expand.grid(mtry = c(2, 3, 4))
folds <- 5
trainControl <- trainControl(method = "cv", number = folds)
# Training mit k-fold Cross-Validation
rfModel <- train(SalePrice ~ ., data = df, method = "ranger", trControl = trainControl, tuneGrid = rfGrid)
# Zeige die Ergebnisse der k-fold Cross-Validation
print(rfModel$results)
# Überprüfe, ob das Modell erfolgreich trainiert wurde
if (!is.null(rfModel)) {
# Zeige eine Zusammenfassung des trainierten Modells
print(rfModel)
# Zeige die Ergebnisse der k-fold Cross-Validation
print(rfModel$results)
} else {
# Wenn das Modell nicht erfolgreich trainiert wurde, gib eine entsprechende Meldung aus
print("Das Modell konnte nicht trainiert werden.")
}
#install.packages("caret")
#install.packages("ranger")
library(caret)
library(ranger)
# Gitter von Werten für die abzustimmenden Parameter
rfGrid <- expand.grid(mtry = c(2, 3, 4), splitrule = c("gini", "extratrees"), min.node.size = c(1, 5, 10))
folds <- 5
trainControl <- trainControl(method = "cv", number = folds)
# Training mit k-fold Cross-Validation
rfModel <- train(SalePrice ~ ., data = df, method = "ranger", trControl = trainControl, tuneGrid = rfGrid)
# Überprüfe, ob das Modell erfolgreich trainiert wurde
if (!is.null(rfModel)) {
# Zeige eine Zusammenfassung des trainierten Modells
print(rfModel)
# Zeige die Ergebnisse der k-fold Cross-Validation
print(rfModel$results)
} else {
# Wenn das Modell nicht erfolgreich trainiert wurde, gib eine entsprechende Meldung aus
print("Das Modell konnte nicht trainiert werden.")
}
# Zeige die Ergebnisse der k-fold Cross-Validation
print(rfModel$results)
# Überprüfe, ob das Modell erfolgreich trainiert wurde
if (!is.null(rfModel)) {
# Zeige eine Zusammenfassung des trainierten Modells
print(rfModel)
# Zeige die Ergebnisse der k-fold Cross-Validation
print(rfModel$results)
} else {
# Wenn das Modell nicht erfolgreich trainiert wurde, gib eine entsprechende Meldung aus
print("Das Modell konnte nicht trainiert werden.")
}
# Berechne die Vorhersagen des Modells auf den Testdaten
predictions <- predict(rfModel, newdata = test_data)
# Lade das Paket caret, falls es nicht bereits geladen ist
library(caret)
# Berechne die Vorhersagen des Modells auf den Testdaten
predictions <- predict(rfModel, newdata = test_data)
# Berechne die Confusion Matrix und zeige sie an
conf_matrix <- confusionMatrix(predictions, test$SalePrice)
# Lade das Paket caret, falls es nicht bereits geladen ist
library(caret)
performance(rfModel)
performance_metrics <- tidy(rfModel)
print(performance_metrics)
# Lade das Paket caret, falls es nicht bereits geladen ist
library(caret)
library(ranger)
library(yardstick)
# Lade das Paket caret, falls es nicht bereits geladen ist
install.packages("caret")
install.packages("ranger")
install.packages("yardstick")
install.packages("broom"
library(caret)
install.packages("caret")
install.packages("caret")
# Lade das Paket caret, falls es nicht bereits geladen ist
install.packages("caret")
install.packages("ranger")
install.packages("caret")
install.packages("yardstick")
install.packages("broom")
install.packages("yardstick")
library(caret)
library(ranger)
library(yardstick)
library(broom)
predictions <- predict(rfModel, newdata = df)
performance_metrics <- yardstick::roc_auc(df$SalePrice, predictions)
# Lade das Paket caret, falls es nicht bereits geladen ist
install.packages("yardstick")
install.packages("broom")
library(caret)
library(ranger)
library(yardstick)
library(broom)
predictions <- predict(rfModel, newdata = df)
performance_metrics <- yardstick::roc_auc(df$SalePrice, predictions)
install.packages("yardstick")
install.packages("broom")
# Lade das Paket caret, falls es nicht bereits geladen ist
install.packages("yardstick")
install.packages("broom")
library(caret)
library(ranger)
library(yardstick)
library(broom)
predictions <- predict(rfModel, newdata = df)
performance_metrics <- yardstick::roc_auc(df$SalePrice, predictions)
install.packages("broom")
# Lade das Paket caret, falls es nicht bereits geladen ist
#install.packages("yardstick")
#install.packages("broom")
library(caret)
library(ranger)
library(yardstick)
library(broom)
predictions <- predict(rfModel, newdata = df)
performance_metrics <- yardstick::roc_auc(df$SalePrice, predictions)
#install.packages("caret")
#install.packages("ranger")
library(caret)
library(ranger)
# Gitter von Werten für die abzustimmenden Parameter
rfGrid <- expand.grid(mtry = c(2, 3, 4), splitrule = c("gini", "extratrees"), min.node.size = c(1, 5, 10))
# Erstellen Sie einen Train-Test-Split
set.seed(123) # Für reproduzierbare Ergebnisse
trainIndex <- createDataPartition(df$SalePrice, p = 0.8, list = FALSE)
trainSet <- df[trainIndex, ]
testSet <- df[-trainIndex, ]
# Training mit Train-Test-Split
rfModel <- train(SalePrice ~ ., data = trainSet, method = "ranger", tuneGrid = rfGrid)
# Vorhersagen auf den Testdaten
predictions <- predict(rfModel, newdata = testSet)
#install.packages("caret")
#install.packages("ranger")
library(caret)
library(ranger)
# Gitter von Werten für die abzustimmenden Parameter
rfGrid <- expand.grid(num.trees = c(100, 200, 300), mtry = c(2, 3, 4), replace = c(TRUE, FALSE), sample.fraction = c(0.8, 1.0))
# Erstellen Sie einen Train-Test-Split
set.seed(123) # Für reproduzierbare Ergebnisse
trainIndex <- createDataPartition(df$SalePrice, p = 0.8, list = FALSE)
trainSet <- df[trainIndex, ]
testSet <- df[-trainIndex, ]
# Training mit Train-Test-Split
rfModel <- train(SalePrice ~ ., data = trainSet, method = "ranger", trControl = trainControl(method = "cv", number = 5), tuneGrid = rfGrid)
#install.packages("caret")
#install.packages("ranger")
library(caret)
library(ranger)
# Gitter von Werten für die abzustimmenden Parameter
rfGrid <- expand.grid(num.trees = c(100, 200, 300), mtry = c(2, 3, 4), replace = c(TRUE, FALSE), sample.fraction = c(0.8, 1.0))
# Erstellen Sie einen Train-Test-Split
set.seed(123) # Für reproduzierbare Ergebnisse
trainIndex <- createDataPartition(df$SalePrice, p = 0.8, list = FALSE)
trainSet <- df[trainIndex, ]
testSet <- df[-trainIndex, ]
# Training mit Train-Test-Split
rfModel <- train(SalePrice ~ ., data = trainSet, method = "ranger", trControl = trainControl(method = "cv", number = 5), tuneGrid = rfGrid)
#install.packages("caret")
#install.packages("ranger")
library(caret)
library(ranger)
# Gitter von Werten für die abzustimmenden Parameter
rfGrid <- expand.grid(mtry = c(2, 3, 4),
num.trees = c(100, 200, 300),
replace = c(TRUE, FALSE),
sample.fraction = c(0.8, 1.0))
# Erstellen Sie einen Train-Test-Split
set.seed(123) # Für reproduzierbare Ergebnisse
trainIndex <- createDataPartition(df$SalePrice, p = 0.8, list = FALSE)
trainSet <- df[trainIndex, ]
testSet <- df[-trainIndex, ]
# Training mit Train-Test-Split
rfModel <- train(SalePrice ~ .,
data = trainSet,
method = "ranger",
trControl = trainControl(method = "cv", number = 5),
tuneGrid = rfGrid)
#install.packages("caret")
#install.packages("ranger")
library(caret)
library(ranger)
# Gitter von Werten für die abzustimmenden Parameter
rfGrid <- expand.grid(mtry = c(2, 3, 4),
splitrule = c("gini", "extratrees"),
min.node.size = c(1, 5, 10))
# Erstellen Sie einen Train-Test-Split
set.seed(123) # Für reproduzierbare Ergebnisse
trainIndex <- createDataPartition(df$SalePrice, p = 0.8, list = FALSE)
trainSet <- df[trainIndex, ]
testSet <- df[-trainIndex, ]
# Training mit Train-Test-Split
rfModel <- train(SalePrice ~ .,
data = trainSet,
method = "ranger",
trControl = trainControl(method = "cv", number = 5),
tuneGrid = rfGrid)
# Vorhersagen auf den Testdaten
predictions <- predict(rfModel, newdata = testSet)
#install.packages("caret")
#install.packages("ranger")
library(caret)
library(ranger)
# Gitter von Werten für die abzustimmenden Parameter
rfGrid <- expand.grid(mtry = c(2, 3, 4),
splitrule = c("variance"),
min.node.size = c(1, 5, 10))
# Erstellen Sie einen Train-Test-Split
set.seed(123) # Für reproduzierbare Ergebnisse
trainIndex <- createDataPartition(df$SalePrice, p = 0.8, list = FALSE)
trainSet <- df[trainIndex, ]
testSet <- df[-trainIndex, ]
# Training mit Train-Test-Split
rfModel <- train(SalePrice ~ .,
data = trainSet,
method = "ranger",
trControl = trainControl(method = "cv", number = 5),
tuneGrid = rfGrid)
# Vorhersagen auf den Testdaten
predictions <- predict(rfModel, newdata = testSet)
#install.packages("caret")
#install.packages("ranger")
library(caret)
library(ranger)
# Gitter von Werten für die abzustimmenden Parameter
rfGrid <- expand.grid(mtry = c(2, 3, 4),
splitrule = c("variance"),
min.node.size = c(1, 5, 10))
# Erstellen Sie einen Train-Test-Split
set.seed(123) # Für reproduzierbare Ergebnisse
trainIndex <- createDataPartition(df$SalePrice, p = 0.8, list = FALSE)
trainSet <- df[trainIndex, ]
testSet <- df[-trainIndex, ]
# Training mit Train-Test-Split
rfModel <- train(SalePrice ~ .,
data = trainSet,
method = "ranger",
trControl = trainControl(method = "cv", number = 5),
tuneGrid = rfGrid)
# Vorhersagen auf den Testdaten
predictions <- predict(rfModel, newdata = testSet)
#install.packages("caret")
#install.packages("ranger")
library(caret)
library(ranger)
# Gitter von Werten für die abzustimmenden Parameter
rfGrid <- expand.grid(mtry = c(2, 3, 4),
splitrule = c("variance"),
min.node.size = c(1, 5, 10))
# Erstellen Sie einen Train-Test-Split
set.seed(124) # Für reproduzierbare Ergebnisse
trainIndex <- createDataPartition(df$SalePrice, p = 0.8, list = FALSE)
trainSet <- df[trainIndex, ]
testSet <- df[-trainIndex, ]
# Training mit Train-Test-Split
rfModel <- train(SalePrice ~ .,
data = trainSet,
method = "ranger",
trControl = trainControl(method = "cv", number = 5),
tuneGrid = rfGrid)
# Vorhersagen auf den Testdaten
predictions <- predict(rfModel, newdata = testSet)
# Berechnen der Leistungsmetriken
# Für Regression können wir RMSE (Root Mean Squared Error) oder MAE (Mean Absolute Error) verwenden
rmse <- sqrt(mean((predictions - testSet$SalePrice)^2))
mae <- mean(abs(predictions - testSet$SalePrice))
print(paste("RMSE: ", round(rmse, 2)))
print(paste("MAE: ", round(mae, 2)))
# Weitere Leistungsmetriken können hier hinzugefügt werden, z.B. R-Quadrat, etc.
#install.packages("caret")
#install.packages("ranger")
library(caret)
library(ranger)
# Gitter von Werten für die abzustimmenden Parameter
rfGrid <- expand.grid(mtry = c(2, 3, 4),
splitrule = c("variance"),
min.node.size = c(1, 5, 10))
# Erstellen Sie einen Train-Test-Split
set.seed(123) # Für reproduzierbare Ergebnisse
trainIndex <- createDataPartition(df$SalePrice, p = 0.8, list = FALSE)
trainSet <- df[trainIndex, ]
testSet <- df[-trainIndex, ]
# Training mit Train-Test-Split
rfModel <- train(SalePrice ~ .,
data = trainSet,
method = "ranger",
trControl = trainControl(method = "cv", number = 5),
tuneGrid = rfGrid)
# Vorhersagen auf den Testdaten
predictions <- predict(rfModel, newdata = testSet)
#install.packages("caret")
#install.packages("ranger")
library(caret)
library(ranger)
# Gitter von Werten für die abzustimmenden Parameter
rfGrid <- expand.grid(mtry = c(2, 3, 4),
splitrule = c("variance"),
min.node.size = c(1, 5, 10))
# Erstellen Sie einen Train-Test-Split
set.seed(187) # Für reproduzierbare Ergebnisse
trainIndex <- createDataPartition(df$SalePrice, p = 0.8, list = FALSE)
trainSet <- df[trainIndex, ]
testSet <- df[-trainIndex, ]
# Training mit Train-Test-Split
rfModel <- train(SalePrice ~ .,
data = trainSet,
method = "ranger",
trControl = trainControl(method = "cv", number = 5),
tuneGrid = rfGrid)
# Vorhersagen auf den Testdaten
predictions <- predict(rfModel, newdata = testSet)
#install.packages("caret")
#install.packages("ranger")
library(caret)
library(ranger)
# Gitter von Werten für die abzustimmenden Parameter
rfGrid <- expand.grid(mtry = c(2, 3, 4),
splitrule = c("variance"),
min.node.size = c(1, 5, 10))
# Erstellen Sie einen Train-Test-Split
set.seed(124) # Für reproduzierbare Ergebnisse
trainIndex <- createDataPartition(df$SalePrice, p = 0.8, list = FALSE)
trainSet <- df[trainIndex, ]
testSet <- df[-trainIndex, ]
# Training mit Train-Test-Split
rfModel <- train(SalePrice ~ .,
data = trainSet,
method = "ranger",
trControl = trainControl(method = "cv", number = 5),
tuneGrid = rfGrid)
# Vorhersagen auf den Testdaten
predictions <- predict(rfModel, newdata = testSet)
# Berechnen der Leistungsmetriken
# Für Regression können wir RMSE (Root Mean Squared Error) oder MAE (Mean Absolute Error) verwenden
rmse <- sqrt(mean((predictions - testSet$SalePrice)^2))
mae <- mean(abs(predictions - testSet$SalePrice))
print(paste("RMSE: ", round(rmse, 2)))
print(paste("MAE: ", round(mae, 2)))
# Weitere Leistungsmetriken können hier hinzugefügt werden, z.B. R-Quadrat, etc.
# Lade das Paket caret, falls es nicht bereits geladen ist
#install.packages("yardstick")
#install.packages("broom")
library(yardstick)
library(broom)
# Berechnen der Leistungsmetriken mit defaultSummary()
model_summary <- defaultSummary(predictions, testSet$SalePrice)
# Umwandeln von testSet$SalePrice in einen Vektor
actual_values <- as.vector(testSet$SalePrice)
# Lade das Paket caret, falls es nicht bereits geladen ist
#install.packages("yardstick")
#install.packages("broom")
library(yardstick)
library(broom)
# Umwandeln von testSet$SalePrice in einen Vektor
actual_values <- as.vector(testSet$SalePrice)
# Berechnen der Leistungsmetriken mit defaultSummary()
model_summary <- defaultSummary(predictions, actual_values)
# Lade das Paket caret, falls es nicht bereits geladen ist
#install.packages("yardstick")
#install.packages("broom")
library(yardstick)
library(broom)
# Umwandeln von testSet$SalePrice in einen Vektor
actual_values <- as.vector(testSet$SalePrice)
# Berechnen der Leistungsmetriken mit defaultSummary()
model_summary <- defaultSummary(predictions, actual_values)
# Lade das Paket caret, falls es nicht bereits geladen ist
#install.packages("yardstick")
#install.packages("broom")
library(yardstick)
library(broom)
# Umwandeln von testSet$SalePrice in einen Vektor
actual_values <- unlist(testSet$SalePrice)
# Berechnen der Leistungsmetriken mit defaultSummary()
model_summary <- defaultSummary(predictions, actual_values)
