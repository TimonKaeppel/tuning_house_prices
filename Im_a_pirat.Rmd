# Lade die CSV-Dateien

```{r}
df <- read.csv("resources/house_prices.csv")

```

# Zeige die ersten paar Zeilen der geladenen Daten an

```{r}
print(head(df))
```

```{r}

```
# Default-Werte für die Parameter des Random Forest-Algorithmus:
num.trees: 500
mtry: sqrt(number of variables) (für Regression) = 8
sample.fraction: 0.632 (für Regression)
min.node.size: 5 (für Regression)
replace: FALSE

```{r}
# Train-Test-Split
set.seed(124) # Für reproduzierbare Ergebnisse
trainIndex <- createDataPartition(df$SalePrice, p = 0.8, list = FALSE)
trainSet <- df[trainIndex, ]
testSet <- df[-trainIndex, ]

# Initialisieren Sie ein Dataframe, um die Ergebnisse zu speichern

#   num.trees = numeric(),
# mtry = numeric(),
# sample.fraction = numeric(),
# min.bucket = numeric(),
# replace = logical(),

results_tuning <- data.frame(
  Parameter = character(),
  Value = numeric(),
  MSE = numeric(),
  runtime_training = numeric(),
  runtime_prediction = numeric()
)

# Liste der zu testenden Parameterwerte
num.trees_values <- c(1:150, 256, 512, 1024, 2048)
mtry_values <- seq(1, 60, 1)
sample.fraction_values <- seq(0.01, 1, 0.01)
min.node.size_values <- seq(1, 50, 1)
replace_values <- c(TRUE, FALSE)

# Tuning für num.trees
for (val in num.trees_values) {
  set.seed(124)
  runtime_training <- system.time({
    model <- ranger(SalePrice ~ ., data = trainSet, num.trees = val)
  })[3]
  runtime_prediction <- system.time({
    pred <- predict(model, data = testSet)$predictions
  })[3]
  mse <- mean((pred - testSet$SalePrice)^2) # Berechnung des MSE
  results_tuning <- rbind(results_tuning, 
                  data.frame(Parameter= num.trees,
                            Value = val, 
                            MSE = mse, 
                            runtime_prediction = runtime_prediction, 
                            runtime_training = runtime_training))
}

# Tuning für mtry
for (val in mtry_values) {
  set.seed(124)
  runtime_training <- system.time({
    model <- ranger(SalePrice ~ ., data = trainSet, mtry = val)
  })[3]
  runtime_prediction <- system.time({
    pred <- predict(model, data = testSet)$predictions
  })[3]
  mse <- mean((pred - testSet$SalePrice)^2) # Berechnung des MSE
  results_tuning <- rbind(results_tuning, 
                   data.frame(Parameter= mtry,
                              Value = val, 
                              MSE = mse, 
                              runtime_prediction = runtime_prediction, 
                              runtime_training = runtime_training))
}

# Tuning für sample.fraction
for (val in sample.fraction_values) {
  set.seed(124)
  runtime_training <- system.time({
    model <- ranger(SalePrice ~ ., data = trainSet, sample.fraction = val)
  })[3]
  runtime_prediction <- system.time({
    pred <- predict(model, data = testSet)$predictions
  })[3]
  mse <- mean((pred - testSet$SalePrice)^2) # Berechnung des MSE
  results_tuning <- rbind(results_tuning, 
                   data.frame(Parameter= sample.fractions,
                              Value = val,
                              MSE = mse,
                              runtime_prediction = runtime_prediction, 
                              runtime_training = runtime_training))
}

# Tuning für min.node.size
for (val in min.node.size_values) {
  set.seed(124)
  runtime_training <- system.time({
    model <- ranger(SalePrice ~ ., data = trainSet, min.node.size =  = val)
  })[3]
  runtime_prediction <- system.time({
    pred <- predict(model, data = testSet)$predictions
  })[3]
  mse <- mean((pred - testSet$SalePrice)^2) # Berechnung des MSE
  results_tuning <- rbind(results_tuning, 
                   data.frame(Parameter= min.node.size,
                              Value = val 
                              MSE = mse, 
                              runtime_prediction = runtime_prediction, 
                              runtime_training = runtime_training))
}

# Tuning für replace
for (val in replace_values) {
  set.seed(124)
  runtime_training <- system.time({
    model <- ranger(SalePrice ~ ., data = trainSet, replace = val)
  })[3]
  runtime_prediction <- system.time({
    pred <- predict(model, data = testSet)$predictions
  })[3]
  mse <- mean((pred - testSet$SalePrice)^2) # Berechnung des MSE
  results_tuning <- rbind(results_tuning, 
                   data.frame(Parameter= replace,
                              Value = val, 
                              MSE = mse, 
                              runtime_prediction = runtime_prediction, 
                              runtime_training = runtime_training))
}

# Ausgabe der Ergebnisse
print(results_tuning)

# Ausgabe der besten Werte für jeden Parameter
#best_values <- aggregate(MSE ~ Parameter, data = results, min)
#print(best_values)
```

```{r}
write.csv(results, file = "results_solo_with_higher_range.csv", row.names = FALSE)
```

```{r}
library(ranger)
library(caret)
# Erstellen Sie ein Gitter aller möglichen Kombinationen von Parametern
paramGrid <- expand.grid(num.trees = num.trees_values,
                         mtry = mtry_values,
                         sample.fraction = sample.fraction_values,
                         min.node.size = min.bucket_values,
                         replace = replace_values)

# Initialisieren Sie ein Dataframe, um die Ergebnisse zu speichern
results_all_params <- data.frame()

# Trainieren Sie das Modell für jede Kombination von Parametern
for (i in 1:nrow(paramGrid)) {
  set.seed(124)
  runtime_training <- system.time({
    model <- ranger(SalePrice ~ ., data = trainSet,
                    num.trees = paramGrid$num.trees[i],
                    mtry = paramGrid$mtry[i],
                    sample.fraction = paramGrid$sample.fraction[i],
                    min.node.size = paramGrid$min.node.size[i],
                    replace = paramGrid$replace[i])
  })[3]
  runtime_prediction <- system.time({
    pred <- predict(model, data = testSet)$predictions
  })[3]
  mse <- mean((pred - testSet$SalePrice)^2) # Berechnung des MSE
  results_all_params <- rbind(results_all_params, cbind(paramGrid[i, ], MSE = mse, 
                                                        runtime_training = runtime_training, 
                                                        runtime_prediction = runtime_prediction))
}

# Finden Sie die Kombination von Parametern mit dem niedrigsten MSE
best_params <- results_all_params[which.min(results$MSE), ]
print(best_params)

```
# best.params = numtrees = 2048, mtry = 2, sample.fraction = 0.1, min.node.size = 1, replace = TRUE
# MSE = 1009052495

```{r}
write.csv(results_all_params, file = "results_all_params.csv", row.names = FALSE)

```

```{r}

```