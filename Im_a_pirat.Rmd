# Lade die CSV-Dateien

```{r}

#train <- read.csv("D:/Documents/DHBW Ravensburg/6. Semester/Tuning von Algorithmen/tuning_house_prices/resources/train.csv")

#test <- read.csv("D:/Documents/DHBW Ravensburg/6. Semester/Tuning von Algorithmen/tuning_house_prices/resources/test.csv")

#solution <- read.csv("D:/Documents/DHBW Ravensburg/6. Semester/Tuning von Algorithmen/tuning_house_prices/resources/solution.csv")

df <- read.csv("D:/Documents/DHBW Ravensburg/6. Semester/Tuning von Algorithmen/tuning_house_prices/resources/house_prices_df.csv")

```


# Zeige die ersten paar Zeilen der geladenen Daten an

```{r}
print(head(df))
```

```{r}

```
# Default-Werte für die Parameter des Random Forest-Algorithmus:
num.trees: 500
mtry: sqrt(number of variables)
sample.fraction: 0.632 (für Regression)
min.node.size: 5 (für Regression)
replace: FALSE

```{r}
# Train-Test-Split
set.seed(124) # Für reproduzierbare Ergebnisse
trainIndex <- createDataPartition(df$SalePrice, p = 0.8, list = FALSE)
trainSet <- df[trainIndex, ]
testSet <- df[-trainIndex, ]

# Initialisieren Sie ein Dataframe, um die Ergebnisse zu speichern
results <- data.frame()

# Liste der zu testenden Parameterwerte
num.trees_values <- c(500, 1000, 1500)
mtry_values <- c(2, 3, 4)
sample.fraction_values <- seq(0.5, 1, 0.1)
min.bucket_values <- c(1, 5, 10)
replace_values <- c(TRUE, FALSE)

# Tuning für num.trees
for (val in num.trees_values) {
  set.seed(124)
  model <- ranger(SalePrice ~ ., data = trainSet, num.trees = val)
  pred <- predict(model, data = testSet)$predictions
  mse <- mean((pred - testSet$SalePrice)^2) # Berechnung des MSE
  results <- rbind(results, data.frame(Parameter = "num.trees", Value = val, MSE = mse))
}

# Tuning für mtry
for (val in mtry_values) {
  set.seed(124)
  model <- ranger(SalePrice ~ ., data = trainSet, mtry = val)
  pred <- predict(model, data = testSet)$predictions
  mse <- mean((pred - testSet$SalePrice)^2) # Berechnung des MSE
  results <- rbind(results, data.frame(Parameter = "mtry", Value = val, MSE = mse))
}

# Tuning für sample.fraction
for (val in sample.fraction_values) {
  set.seed(124)
  model <- ranger(SalePrice ~ ., data = trainSet, sample.fraction = val)
  pred <- predict(model, data = testSet)$predictions
  mse <- mean((pred - testSet$SalePrice)^2) # Berechnung des MSE
  results <- rbind(results, data.frame(Parameter = "sample.fraction", Value = val, MSE = mse))
}

# Tuning für min.bucket
for (val in min.bucket_values) {
  set.seed(124)
  model <- ranger(SalePrice ~ ., data = trainSet, min.node.size = val)
  pred <- predict(model, data = testSet)$predictions
  mse <- mean((pred - testSet$SalePrice)^2) # Berechnung des MSE
  results <- rbind(results, data.frame(Parameter = "min.node.size", Value = val, MSE = mse))
}

# Tuning für replace
for (val in replace_values) {
  set.seed(124)
  model <- ranger(SalePrice ~ ., data = trainSet, replace = val)
  pred <- predict(model, data = testSet)$predictions
  mse <- mean((pred - testSet$SalePrice)^2) # Berechnung des MSE
  results <- rbind(results, data.frame(Parameter = "replace", Value = val, MSE = mse))
}

# Ausgabe der Ergebnisse
print(results)

# Ausgabe der besten Werte für jeden Parameter
best_values <- aggregate(MSE ~ Parameter, data = results, min)
print(best_values)
```

```{r}
write.csv(results, file = "results.csv", row.names = FALSE)
```

```{r}
# Erstellen Sie ein Gitter aller möglichen Kombinationen von Parametern
paramGrid <- expand.grid(num.trees = num.trees_values,
                         mtry = mtry_values,
                         sample.fraction = sample.fraction_values,
                         min.node.size = min.bucket_values,
                         replace = replace_values)

# Initialisieren Sie ein Dataframe, um die Ergebnisse zu speichern
results2 <- data.frame()

# Trainieren Sie das Modell für jede Kombination von Parametern
for (i in 1:nrow(paramGrid)) {
  set.seed(124)
  model <- ranger(SalePrice ~ ., data = trainSet,
                  num.trees = paramGrid$num.trees[i],
                  mtry = paramGrid$mtry[i],
                  sample.fraction = paramGrid$sample.fraction[i],
                  min.node.size = paramGrid$min.node.size[i],
                  replace = paramGrid$replace[i])
  pred <- predict(model, data = testSet)$predictions
  mse <- mean((pred - testSet$SalePrice)^2) # Berechnung des MSE
  results2 <- rbind(results2, cbind(paramGrid[i, ], MSE = mse))
}

# Finden Sie die Kombination von Parametern mit dem niedrigsten MSE
best_params <- results2[which.min(results$MSE), ]
print(best_params)

```

```{r}
write.csv(results2, file = "results2.csv", row.names = FALSE)
```